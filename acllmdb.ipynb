{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import os\r\n",
                "import numpy as np\r\n",
                "\r\n",
                "from sklearn import metrics\r\n",
                "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\r\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\r\n",
                "from sklearn.linear_model import SGDClassifier\r\n",
                "from sklearn.pipeline import Pipeline\r\n",
                "from sklearn.metrics import accuracy_score\r\n",
                "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "chemin=\"D:\\\\IA\\\\EXERCICES\\\\python\\\\IA\\\\Naive Bayes\\\\aclImdb\\\\train\"\r\n",
                "\r\n",
                "\r\n",
                "X, Y=[],[]\r\n",
                "pos_files=os.listdir(chemin+\"\\\\pos\")\r\n",
                "neg_files=os.listdir(chemin+\"\\\\neg\")\r\n",
                "\r\n",
                "for pos in pos_files:\r\n",
                "    fichier=open (chemin+\"\\\\pos\\\\\"+pos,'r', encoding='ascii', errors='ignore')\r\n",
                "    X.append(fichier.read())\r\n",
                "    Y.append(1)\r\n",
                "    fichier.close()\r\n",
                "  \r\n",
                "\r\n",
                "for neg in neg_files:\r\n",
                "    fichier=open (chemin+\"\\\\neg\\\\\"+neg,'r', encoding='ascii', errors='ignore')\r\n",
                "    X.append(fichier.read())\r\n",
                "    Y.append(0)\r\n",
                "    fichier.close()\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.10,random_state=40)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "count_vect=CountVectorizer(stop_words='english')\r\n",
                "X_train_count=count_vect.fit_transform(X_train)\r\n",
                "tfidf_transformer = TfidfTransformer()\r\n",
                "X_train_tfidf = tfidf_transformer.fit_transform(X_train_count)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "#Modèle BernoulliNB\r\n",
                "model = BernoulliNB()\r\n",
                "model.fit(X_train_tfidf, y_train)\r\n",
                "X_test_counts = count_vect.transform(X_test)\r\n",
                "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\r\n",
                "y_pred = model.predict(X_test_tfidf)\r\n",
                "\r\n",
                "print(accuracy_score(y_test, y_pred))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0.8508\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "#Modèle MultinomialNB\r\n",
                "model = MultinomialNB()\r\n",
                "model.fit(X_train_tfidf, y_train)\r\n",
                "\r\n",
                "y_pred = model.predict(X_test_tfidf)\r\n",
                "\r\n",
                "print(accuracy_score(y_test, y_pred))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0.8668\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "#modèle regression logistique \r\n",
                "text_model = Pipeline([('count_vect', CountVectorizer()), \r\n",
                "                     ('tfidf_transformer', TfidfTransformer()),\r\n",
                "                     ('text_model', SGDClassifier(tol=None, loss='log'))])\r\n",
                "\r\n",
                "text_model.fit(X_train, y_train)\r\n",
                "y_pred = text_model.predict(X_test)\r\n",
                "print(accuracy_score(y_test, y_pred))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0.8672\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit"
        },
        "interpreter": {
            "hash": "88ac2394ebfb1498fc5009e3728603c22e948b3a3a8ec13724ed1c353ba8e9f4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}